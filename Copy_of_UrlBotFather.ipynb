{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of UrlBotFather.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMm74Ey50i3bxP29+hyLX35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mark-nick-o/AIML_SoundArtsProject/blob/main/Copy_of_UrlBotFather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKyVMymeFTJC"
      },
      "source": [
        "This is a chatbot using botFather you can send a request and get a url relating to it. \n",
        "many thanks for information to Nikolay Gerasimenko of Skillbox\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1IaIhcFhfXS"
      },
      "source": [
        "import random\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zviV3TIAclg2"
      },
      "source": [
        "#with open('/content/BIG_BOT_CONFIG.json', 'r') as f:\n",
        "#  BOT_CONFIG = json.load(f)\n",
        "\n",
        "#with open('/content/test.txt', 'w') as f:\n",
        "#   f.write('test text')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c1OQzVQXLJx"
      },
      "source": [
        "BOT_CONFIG = {\n",
        "\n",
        "    'threshold': 0.6,\n",
        "\t\n",
        "    'intents': {\n",
        "        'house': {\n",
        "            'examples': [\n",
        "                         'house!',\n",
        "                         'club',\n",
        "                         'garage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '1',\n",
        "                          '2',\n",
        "                          '3'\n",
        "            ]\n",
        "        },\n",
        "        'futuregarage': {\n",
        "            'examples': [\n",
        "                         'ukgarage',\n",
        "                         'futuregarage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'electro': {\n",
        "            'examples': [\n",
        "                         'electronic',\n",
        "                         'electro',\n",
        "                         'eighties',\n",
        "                         'pop',\n",
        "                         'newwave'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'rock': {\n",
        "            'examples': [\n",
        "                         'heavy',\n",
        "                         'rock',\n",
        "                         'metal'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'cartoon': {\n",
        "            'examples': [\n",
        "                         'anime',\n",
        "                         'cartoon',\n",
        "                         'animation',\n",
        "                         'computer art'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '1',\n",
        "                          '3',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'java': {\n",
        "            'examples': [\n",
        "                         'javascript',\n",
        "                         'java',\n",
        "                         'flash',\n",
        "                         'webpage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '21',\n",
        "                          '23',\n",
        "                          '18'\n",
        "            ]\n",
        "        },\n",
        "        'list': {\n",
        "            'examples': [\n",
        "                         'valid',\n",
        "                         'say',\n",
        "                         'examples'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          'list of possible keywords :: rock, cartoon, house, electro, java, future garage,'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    'default': [\n",
        "                'style not known or found please say again or say list for available options',\n",
        "                'i do not have it, you could try speaking slower again,, or list for available categories'\n",
        "    ]\n",
        "\t\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xMUVYhcQtH1",
        "outputId": "241f8f40-26f1-498d-9e07-087862e16180"
      },
      "source": [
        "#X = []\n",
        "#y = []\n",
        "\n",
        "#for intent, value in BOT_CONFIG['intents'].items():\n",
        "#    if 'inc_examples' in value:\n",
        "#      examples = list(set([example.lower() for example in value['inc_examples']]))\n",
        "#    else:\n",
        "#      examples = list(set([example.lower() for example in value['examples']]))\n",
        "#    X += examples\n",
        "#    y += [intent] * len(examples)\n",
        "\n",
        "#vectorizer = TfidfVectorizer()\n",
        "#X_transformed = vectorizer.fit_transform(X)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#classifier = RandomForestClassifier()\n",
        "#classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USaYKrZkec_A"
      },
      "source": [
        "def clean(text):\n",
        "  return ''.join([simbol for simbol in text.lower() if simbol in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz '])\n",
        "\n",
        "def match(example, text):\n",
        "  return nltk.edit_distance(clean(text), clean(example)) / len(example) < BOT_CONFIG['threshold'] if len(example) > 0 else False\n",
        "  # return nltk.edit_distance(clean(text), clean(example)) / len(example) < BOT_CONFIG['threshold']\n",
        "\n",
        "#def get_intent(text):\n",
        "#  for intent, value in BOT_CONFIG['intents'].items():\n",
        "#    print(\"intent was %s\" % intent)\n",
        "#    if 'examples' in value and not intent.find(text) == -1:\n",
        "#        for example in value['examples']:\n",
        "#          if match(example, text):\n",
        "#              return intent\n",
        "#          else:\n",
        "#              return 'not found in examples'\n",
        "#    elif 'inc_examples' in value and not intent.find(text):\n",
        "#        for example in value['inc_examples']:\n",
        "#            if match(example, text):\n",
        "#              return intent\n",
        "#            else:\n",
        "#              return 'not known from inc_examples'        \n",
        "#  return 'no config found'\n",
        "\n",
        "def cleaner(text): # clean the text up\n",
        "    cleaned_text = ''\n",
        "    for ch in text.lower():\n",
        "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz ':\n",
        "            cleaned_text = cleaned_text + ch\n",
        "    return cleaned_text\n",
        "\n",
        "#def get_intent(text): # get the intent from the json file\n",
        "#    for intent in BOT_CONFIG['intents']:\n",
        "#        if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "#             for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "#                  if match(cleaner(text), cleaner(example)):\n",
        "#                       return intent\n",
        "#        elif 'inc_examples' in BOT_CONFIG['intents'][intent]:\n",
        "#             for example in BOT_CONFIG['intents'][intent]['inc_examples']:\n",
        "#                  if match(cleaner(text), cleaner(example)):\n",
        "#                       return intent\n",
        "\n",
        "def get_intent(text):\n",
        "  for intent in BOT_CONFIG['intents'].keys():\n",
        "    for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "      cleaned_example = clean(example)\n",
        "      cleaned_text = clean(text)\n",
        "      if nltk.edit_distance(cleaned_example, cleaned_text) / max(len(cleaned_example), len(cleaned_text), 1) < BOT_CONFIG['threshold']:\n",
        "        return intent\n",
        "  #return 'unknown_intent'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGIWzkU8soup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3c3e2b-1104-4c6d-95c2-85d52c16f1a9"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for intent, value in BOT_CONFIG['intents'].items():\n",
        "    if 'inc_examples' in value:\n",
        "      examples = list(set([example.lower() for example in value['inc_examples']]))\n",
        "    else:\n",
        "      examples = list(set([example.lower() for example in value['examples']]))\n",
        "    X += examples\n",
        "    y += [intent] * len(examples)\n",
        "\n",
        "# X = []\n",
        "# y = []\n",
        "# for intent in BOT_CONFIG['intents']:\n",
        "#    for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "#        X.append(example)\n",
        "#        y.append(intent)\n",
        "\n",
        "#X = []\n",
        "#y = []\n",
        "#for intent in BOT_CONFIG['intents']:\n",
        "#     if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "#          X += BOT_CONFIG['intents'][intent]['examples']\n",
        "#          y += [intent for i in range(len(BOT_CONFIG['intents'][intent]['examples']))]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "#\n",
        "# most models use this TfidVectoriser\n",
        "#\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))                #CountVectorizer(analyzer='char', ngram_range=(1,3), preprocessor=clean)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "#\n",
        "# count vectoriser is used by SGD classification\n",
        "#\n",
        "vectorizer2 = CountVectorizer(analyzer='char', preprocessor=cleaner, ngram_range=(1,3), stop_words=['а', 'и'])\n",
        "vectorizer2.fit(X)\n",
        "X_vect3 = vectorizer2.transform(X)\n",
        "X_train_vect3, X_test_vect3, y_train3, y_test3 = train_test_split(X_vect3, y, test_size=0.3)\n",
        "sgd = SGDClassifier() # Создаем модель\n",
        "# sgd.fit(X_train_vect, y_train) # Обучаем модель\n",
        "# sgd.score(X_test_vect, y_test) # Проверяем качество модели на тестовой выборке\n",
        "sgd.fit(X_vect3, y)\n",
        "sgd.score(X_vect3, y) # Смотрим качество классификации\n",
        "\n",
        "# ======================================================================================== \n",
        "# different methods gave various answers so we collated the answers and selected variants\n",
        "# ========================================================================================\n",
        "\n",
        "#\n",
        "# use ridge classifier and TfidVectoriser\n",
        "#\n",
        "clf = RidgeClassifier()                                                         #RandomForestClassifier() #RidgeClassifier() #LogisticRegression()\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "clf.score(X_train_vectorized, y_train), clf.score(X_test_vectorized, y_test)\n",
        "\n",
        "#\n",
        "# use random forrest classifier and TfidVectoriser\n",
        "#\n",
        "clf2 = RandomForestClassifier()                                                 #RidgeClassifier() #LogisticRegression()\n",
        "clf2.fit(X_train_vectorized, y_train)\n",
        "clf2.score(X_train_vectorized, y_train), clf2.score(X_test_vectorized, y_test)\n",
        "\n",
        "#\n",
        "# this is an alternative method using random forrest with a differnt test/train split but still TfidVectoriser\n",
        "#\n",
        "vectorizer2 = TfidfVectorizer()\n",
        "X_transformed2 = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_transformed2, y, test_size=0.2, random_state=42)\n",
        "\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train2, y_train2)\n",
        "\n",
        "#\n",
        "# SGDClassifier with CountVectoriser\n",
        "#\n",
        "sgd = SGDClassifier() # Создаем модель\n",
        "# sgd.fit(X_train_vect, y_train) # Обучаем модель\n",
        "# sgd.score(X_test_vect, y_test) # Проверяем качество модели на тестовой выборке\n",
        "sgd.fit(X_vect3, y)\n",
        "sgd.score(X_vect3, y) # Смотрим качество классификации"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwvzrmOceeEP",
        "outputId": "ab7b9867-b7b0-43ef-ca81-e40a8a96052b"
      },
      "source": [
        "question = input()\n",
        "answer = get_intent(question)\n",
        "print(answer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "huaz\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3TE8zmFJkXj"
      },
      "source": [
        "# get intent using ridge classifier model1\n",
        "#\n",
        "def get_intent_by_rc_model1(text):\n",
        "  vectorized_text = vectorizer.transform([text])\n",
        "  return clf.predict(vectorized_text)[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6UcbJNod0oS"
      },
      "source": [
        "# get intent using random forrest model 1\n",
        "#\n",
        "def get_intent_by_rf_model1(text):\n",
        "  vectorized_text = vectorizer.transform([text])\n",
        "  return clf2.predict(vectorized_text)[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zolGvBIxgWf"
      },
      "source": [
        "# get intent using random forrest model 2\n",
        "#\n",
        "def get_intent_by_rf_model2(text):\n",
        "  return classifier.predict(vectorizer.transform([text]))[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLjFDA2H8ljE"
      },
      "source": [
        "# get intent using sgd classification and countVectoriser\n",
        "#\n",
        "def get_intent_by_sgd_model1(text): # Функция определяющая интент текста с помощью ML-модели\n",
        "     return sgd.predict(vectorizer.transform([text]))[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cjg5-cnKNvr"
      },
      "source": [
        "#\n",
        "# use the ridge classifier model 1\n",
        "#\n",
        "def bot_rc_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rc_model1(text)\n",
        "\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5GpD2fKeHf5"
      },
      "source": [
        "#\n",
        "# use the random forrest model 1\n",
        "#\n",
        "def bot_rf_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rf_model1(text)\n",
        "\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptaTRJuS6R42"
      },
      "source": [
        "#\n",
        "# use the random forrest model 2\n",
        "#\n",
        "def bot_rf_ml2(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rf_model2(text)\n",
        "\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_RGEEbz9SPU"
      },
      "source": [
        "#\n",
        "# use the sgd model 1\n",
        "#\n",
        "def bot_sgd_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_sgd_model1(text)\n",
        "\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlsy8StyknwQ",
        "outputId": "2912e3d9-1d04-455e-b24e-1c908d9602f3"
      },
      "source": [
        "choiceVar = 0\n",
        "question = ''\n",
        "while question != 'exit':\n",
        "  question = input()\n",
        "  if question.find(cleaner('exit')) == -1:       \n",
        "    if choiceVar == 0:\n",
        "      print(\"bot1 rcml1\")\n",
        "      response = bot_rc_ml1(question)\n",
        "    elif choiceVar == 1:\n",
        "      print(\"bot2 rfml1\")\n",
        "      response = bot_rf_ml1(question)\n",
        "    elif choiceVar == 2:\n",
        "      print(\"bot3 rfml2\")\n",
        "      response = bot_rf_ml2(question)\n",
        "    else:\n",
        "      print(\"bot4 sgdml1\")\n",
        "      response = bot_sgd_ml1(question)\n",
        "    choiceVar = choiceVar + 1\n",
        "    choiceVar = choiceVar % 4\n",
        "    print(response)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "haus\n",
            "bot1 rcml1\n",
            "3\n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6dsrDPMjbcV"
      },
      "source": [
        "#\n",
        "# This is the bot which will run the AIML\n",
        "#\n",
        "def bot(question,choiceVar):\n",
        "\n",
        "  if question.find(cleaner('exit')) == -1:       \n",
        "    if choiceVar == 0:\n",
        "      print(\"bot1 rcml1\")\n",
        "      response = bot_rc_ml1(question)\n",
        "    elif choiceVar == 1:\n",
        "      print(\"bot2 rfml1\")\n",
        "      response = bot_rf_ml1(question)\n",
        "    elif choiceVar == 2:\n",
        "      print(\"bot3 rfml2\")\n",
        "      response = bot_rf_ml2(question)\n",
        "    else:\n",
        "      print(\"bot4 sgdml1\")\n",
        "      response = bot_sgd_ml1(question)\n",
        "    return response\n",
        "  else:\n",
        "    return 'exit'      "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnwEr8ohjtdr",
        "outputId": "6432fdea-7584-4f50-dc5f-3c11de83138d"
      },
      "source": [
        "#\n",
        "# test it here\n",
        "#\n",
        "choiceVar = 0\n",
        "question = ''\n",
        "while question != 'exit':\n",
        "  question = input()\n",
        "  print(bot(question,choiceVar))\n",
        "  choiceVar = choiceVar + 1\n",
        "  choiceVar = choiceVar % 4\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hause\n",
            "bot1 rcml1\n",
            "3\n",
            "exit\n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7p7PtGzkewq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcb4106-cc0e-49c7-9a97-b62dcf3d572a"
      },
      "source": [
        "pip install python-telegram-bot --upgrade"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (6.1)\n",
            "Requirement already satisfied, skipping upgrade: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuaT9rmGkjZw"
      },
      "source": [
        "import logging\n",
        "\n",
        "from telegram import Update, ForceReply\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "choiceVar = 0\n",
        "\n",
        "# Enable logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "questions = []\n",
        "\n",
        "# Define a few command handlers. These usually take the two arguments update and\n",
        "# context.\n",
        "def start(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
        "    user = update.effective_user\n",
        "    update.message.reply_markdown_v2(\n",
        "        fr'Hi {user.mention_markdown_v2()}\\!',\n",
        "        reply_markup=ForceReply(selective=True),\n",
        "    )\n",
        "\n",
        "\n",
        "def help_command(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
        "    reply = '/content/sample_data/README.md'\n",
        "    update.message.reply_text(reply)\n",
        "\n",
        "\n",
        "def echo(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Echo the user message.\"\"\"\n",
        "    question = update.message.text\n",
        "    questions.append(question)\n",
        "    reply = bot(question,choiceVar)\n",
        "    choiceVar = choiceVar + 1\n",
        "    choiceVar = choiceVar % 4\n",
        "    # to send a file ..... reply = 'https://colab.research.google.com/drive/1Azj_M62pXee_7DlknRx7nEqEB2j7SoFp#scrollTo=zuaT9rmGkjZw'\n",
        "    if not reply.find(\"list\") == -1 or not reply.find(\"reply\") == -1:\n",
        "        #reply = '/content/sample_data/BT012.jpg'\n",
        "        update,message.reply_text(reply)\n",
        "    else:\n",
        "        replyurl = '127.0.0.1:8080/redirect/' + reply\n",
        "        update.message.reply_text(replyurl)      \n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"Start the bot.\"\"\"\n",
        "    # Create the Updater and pass it your bot's token.\n",
        "    updater = Updater(\"1778043544:AAE7NZYNTOqLMWmSFB0jGIv2-vFuNxgBz68\")\n",
        "\n",
        "    # Get the dispatcher to register handlers\n",
        "    dispatcher = updater.dispatcher\n",
        "\n",
        "    # on different commands - answer in Telegram\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
        "\n",
        "    # on non command i.e message - echo the message on Telegram\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
        "\n",
        "    # Start the Bot\n",
        "    updater.start_polling()\n",
        "\n",
        "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
        "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
        "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
        "    updater.idle()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdmmi1YlcQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e50e68f-a375-426d-eec2-3dc54ec254c6"
      },
      "source": [
        "#\n",
        "# run communication to the botFather\n",
        "#\n",
        "choiceVar = 0\n",
        "main()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-14 18:06:09,317 - apscheduler.scheduler - INFO - Scheduler started\n",
            "2021-07-14 18:06:17,545 - telegram.ext.dispatcher - ERROR - No error handlers are registered, logging exception.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/telegram/ext/dispatcher.py\", line 555, in process_update\n",
            "    handler.handle_update(update, self, check, context)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/telegram/ext/handler.py\", line 198, in handle_update\n",
            "    return self.callback(update, context)\n",
            "  File \"<ipython-input-20-b3505c71fa48>\", line 37, in echo\n",
            "    reply = bot(question,choiceVar)\n",
            "UnboundLocalError: local variable 'choiceVar' referenced before assignment\n",
            "2021-07-14 18:06:25,169 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
            "2021-07-14 18:06:25,175 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}