{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of UrlBotFather.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNciMMpsMLI92VTLbL/O9DR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mark-nick-o/AIML_SoundArtsProject/blob/main/Copy_of_UrlBotFather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKyVMymeFTJC"
      },
      "source": [
        "This is a chatbot using botFather you can send a request and get a url relating to it. \n",
        "many thanks for information to Nikolay Gerasimenko of Skillbox\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1IaIhcFhfXS"
      },
      "source": [
        "import random\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zviV3TIAclg2"
      },
      "source": [
        "#with open('/content/BIG_BOT_CONFIG.json', 'r') as f:\n",
        "#  BOT_CONFIG = json.load(f)\n",
        "\n",
        "#with open('/content/test.txt', 'w') as f:\n",
        "#   f.write('test text')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c1OQzVQXLJx"
      },
      "source": [
        "BOT_CONFIG = {\n",
        "\n",
        "    'threshold': 0.6,\n",
        "\t\n",
        "    'intents': {\n",
        "        'house': {\n",
        "            'examples': [\n",
        "                         'house!',\n",
        "                         'club',\n",
        "                         'garage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '1',\n",
        "                          '2',\n",
        "                          '3'\n",
        "            ]\n",
        "        },\n",
        "        'futuregarage': {\n",
        "            'examples': [\n",
        "                         'ukgarage',\n",
        "                         'futuregarage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'electro': {\n",
        "            'examples': [\n",
        "                         'electronic',\n",
        "                         'electro',\n",
        "                         'eighties',\n",
        "                         'pop',\n",
        "                         'newwave'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'rock': {\n",
        "            'examples': [\n",
        "                         'heavy',\n",
        "                         'rock',\n",
        "                         'metal'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '6',\n",
        "                          '7',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'cartoon': {\n",
        "            'examples': [\n",
        "                         'anime',\n",
        "                         'cartoon',\n",
        "                         'animation',\n",
        "                         'computer art'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '1',\n",
        "                          '3',\n",
        "                          '8'\n",
        "            ]\n",
        "        },\n",
        "        'java': {\n",
        "            'examples': [\n",
        "                         'javascript',\n",
        "                         'java',\n",
        "                         'flash',\n",
        "                         'webpage'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          '21',\n",
        "                          '23',\n",
        "                          '18'\n",
        "            ]\n",
        "        },\n",
        "        'list': {\n",
        "            'examples': [\n",
        "                         'valid',\n",
        "                         'say',\n",
        "                         'examples'\n",
        "            ],\n",
        "            'responses': [\n",
        "                          'list of possible keywords :: rock, cartoon, house, electro, java, future garage,'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    'default': [\n",
        "                'style not known or found please say again or say list for available options',\n",
        "                'i do not have it, you could try speaking slower again,, or list for available categories'\n",
        "    ]\n",
        "\t\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xMUVYhcQtH1",
        "outputId": "241f8f40-26f1-498d-9e07-087862e16180"
      },
      "source": [
        "#X = []\n",
        "#y = []\n",
        "\n",
        "#for intent, value in BOT_CONFIG['intents'].items():\n",
        "#    if 'inc_examples' in value:\n",
        "#      examples = list(set([example.lower() for example in value['inc_examples']]))\n",
        "#    else:\n",
        "#      examples = list(set([example.lower() for example in value['examples']]))\n",
        "#    X += examples\n",
        "#    y += [intent] * len(examples)\n",
        "\n",
        "#vectorizer = TfidfVectorizer()\n",
        "#X_transformed = vectorizer.fit_transform(X)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#classifier = RandomForestClassifier()\n",
        "#classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USaYKrZkec_A"
      },
      "source": [
        "def clean(text):\n",
        "  return ''.join([simbol for simbol in text.lower() if simbol in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz '])\n",
        "\n",
        "def match(example, text):\n",
        "  return nltk.edit_distance(clean(text), clean(example)) / len(example) < BOT_CONFIG['threshold' if len(example) > 0 else False\n",
        "  # return nltk.edit_distance(clean(text), clean(example)) / len(example) < BOT_CONFIG['threshold'\n",
        "\n",
        "#def get_intent(text):\n",
        "#  for intent, value in BOT_CONFIG['intents'].items():\n",
        "#    print(\"intent was %s\" % intent)\n",
        "#    if 'examples' in value and not intent.find(text) == -1:\n",
        "#        for example in value['examples']:\n",
        "#          if match(example, text):\n",
        "#              return intent\n",
        "#          else:\n",
        "#              return 'not found in examples'\n",
        "#    elif 'inc_examples' in value and not intent.find(text):\n",
        "#        for example in value['inc_examples']:\n",
        "#            if match(example, text):\n",
        "#              return intent\n",
        "#            else:\n",
        "#              return 'not known from inc_examples'        \n",
        "#  return 'no config found'\n",
        "\n",
        "def cleaner(text): # clean the text up\n",
        "    cleaned_text = ''\n",
        "    for ch in text.lower():\n",
        "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz ':\n",
        "            cleaned_text = cleaned_text + ch\n",
        "    return cleaned_text\n",
        "\n",
        "def get_intent(text): # get the intent from the json file\n",
        "    for intent in BOT_CONFIG['intents']:\n",
        "        if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "             for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "                  if match(cleaner(text), cleaner(example)):\n",
        "                       return intent\n",
        "        elif 'inc_examples' in BOT_CONFIG['intents'][intent]:\n",
        "             for example in BOT_CONFIG['intents'][intent]['inc_examples']:\n",
        "                  if match(cleaner(text), cleaner(example)):\n",
        "                       return intent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGIWzkU8soup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59de11f7-72d9-4fe6-d498-d6af3767bb71"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for intent, value in BOT_CONFIG['intents'].items():\n",
        "    if 'inc_examples' in value:\n",
        "      examples = list(set([example.lower() for example in value['inc_examples']]))\n",
        "    else:\n",
        "      examples = list(set([example.lower() for example in value['examples']]))\n",
        "    X += examples\n",
        "    y += [intent] * len(examples)\n",
        "\n",
        "# X = []\n",
        "# y = []\n",
        "# for intent in BOT_CONFIG['intents']:\n",
        "#    for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "#        X.append(example)\n",
        "#        y.append(intent)\n",
        "\n",
        "#X = []\n",
        "#y = []\n",
        "#for intent in BOT_CONFIG['intents']:\n",
        "#     if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "#          X += BOT_CONFIG['intents'][intent]['examples']\n",
        "#          y += [intent for i in range(len(BOT_CONFIG['intents'][intent]['examples']))]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "#\n",
        "# most models use this TfidVectoriser\n",
        "#\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))                #CountVectorizer(analyzer='char', ngram_range=(1,3), preprocessor=clean)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "#\n",
        "# count vectoriser is used by SGD classification\n",
        "#\n",
        "vectorizer2 = CountVectorizer(analyzer='char', preprocessor=cleaner, ngram_range=(1,3), stop_words=['а', 'и'])\n",
        "vectorizer2.fit(X)\n",
        "X_vect3 = vectorizer2.transform(X)\n",
        "X_train_vect3, X_test_vect3, y_train3, y_test3 = train_test_split(X_vect3, y, test_size=0.3)\n",
        "sgd = SGDClassifier() # Создаем модель\n",
        "# sgd.fit(X_train_vect, y_train) # Обучаем модель\n",
        "# sgd.score(X_test_vect, y_test) # Проверяем качество модели на тестовой выборке\n",
        "sgd.fit(X_vect3, y)\n",
        "sgd.score(X_vect, y) # Смотрим качество классификации\n",
        "\n",
        "# ======================================================================================== \n",
        "# different methods gave various answers so we collated the answers and selected variants\n",
        "# ========================================================================================\n",
        "\n",
        "#\n",
        "# use ridge classifier and TfidVectoriser\n",
        "#\n",
        "clf = RidgeClassifier()                                                         #RandomForestClassifier() #RidgeClassifier() #LogisticRegression()\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "clf.score(X_train_vectorized, y_train), clf.score(X_test_vectorized, y_test)\n",
        "\n",
        "#\n",
        "# use random forrest classifier and TfidVectoriser\n",
        "#\n",
        "clf2 = RandomForestClassifier()                                                 #RidgeClassifier() #LogisticRegression()\n",
        "clf2.fit(X_train_vectorized, y_train)\n",
        "clf2.score(X_train_vectorized, y_train), clf2.score(X_test_vectorized, y_test)\n",
        "\n",
        "#\n",
        "# this is an alternative method using random forrest with a differnt test/train split but still TfidVectoriser\n",
        "#\n",
        "vectorizer2 = TfidfVectorizer()\n",
        "X_transformed2 = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_transformed2, y, test_size=0.2, random_state=42)\n",
        "\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train2, y_train2)\n",
        "\n",
        "#\n",
        "# SGDClassifier with CountVectoriser\n",
        "#\n",
        "sgd = SGDClassifier() # Создаем модель\n",
        "# sgd.fit(X_train_vect, y_train) # Обучаем модель\n",
        "# sgd.score(X_test_vect, y_test) # Проверяем качество модели на тестовой выборке\n",
        "sgd.fit(X_vect3, y)\n",
        "sgd.score(X_vect, y) # Смотрим качество классификации"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwvzrmOceeEP",
        "outputId": "5c4a41da-ef25-4a40-f411-a01a830e87d0"
      },
      "source": [
        "question = input()\n",
        "answer = get_intent(question)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shite\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3TE8zmFJkXj"
      },
      "source": [
        "# get intent using ridge classifier model1\n",
        "#\n",
        "def get_intent_by_rc_model1(text):\n",
        "  vectorized_text = vectorizer.transform([text])\n",
        "  return clf.predict(vectorized_text)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6UcbJNod0oS"
      },
      "source": [
        "# get intent using random forrest model 1\n",
        "#\n",
        "def get_intent_by_rf_model1(text):\n",
        "  vectorized_text = vectorizer.transform([text])\n",
        "  return clf2.predict(vectorized_text)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zolGvBIxgWf"
      },
      "source": [
        "# get intent using random forrest model 2\n",
        "#\n",
        "def get_intent_by_rf_model2(text):\n",
        "  return classifier.predict(vectorizer.transform([text]))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLjFDA2H8ljE"
      },
      "source": [
        "# get intent using sgd classification and countVectoriser\n",
        "#\n",
        "def get_intent_by_sgd_model1(text): # Функция определяющая интент текста с помощью ML-модели\n",
        "     return sgd.predict(vectorizer.transform([text]))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cjg5-cnKNvr"
      },
      "source": [
        "#\n",
        "# use the ridge classifier model 1\n",
        "#\n",
        "def bot_rc_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rc_model1(text)\n",
        "\n",
        "  # if intent == 'unknown_intent':\n",
        "  #   return random.choice(BOT_CONFIG['default'])\n",
        "  # else:\n",
        "  #return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n",
        "  \n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5GpD2fKeHf5"
      },
      "source": [
        "#\n",
        "# use the random forrest model 1\n",
        "#\n",
        "def bot_rf_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rf_model1(text)\n",
        "\n",
        "  # if intent == 'unknown_intent':\n",
        "  #   return random.choice(BOT_CONFIG['default'])\n",
        "  # else:\n",
        "  #return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n",
        "  \n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptaTRJuS6R42"
      },
      "source": [
        "#\n",
        "# use the random forrest model 2\n",
        "#\n",
        "def bot_rf_ml2(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_rf_model2(text)\n",
        "\n",
        "  # if intent == 'unknown_intent':\n",
        "  #   return random.choice(BOT_CONFIG['default'])\n",
        "  # else:\n",
        "  \n",
        "  #return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_RGEEbz9SPU"
      },
      "source": [
        "#\n",
        "# use the sgd model 1\n",
        "#\n",
        "def bot_sgd_ml1(text):\n",
        "\n",
        "  intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
        "\n",
        "  if intent is None:\n",
        "    intent = get_intent_by_sgd_model1(text)\n",
        "\n",
        "  # if intent == 'unknown_intent':\n",
        "  #   return random.choice(BOT_CONFIG['default'])\n",
        "  # else:\n",
        "  \n",
        "  #return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n",
        "  if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "  else: \n",
        "      return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlsy8StyknwQ",
        "outputId": "c14f5ffd-d2fc-40b7-fbc7-073cd00b9299"
      },
      "source": [
        "question = ''\n",
        "while question != 'exit':\n",
        "  question = input()\n",
        "  if question.find(cleaner('exit')) == -1:       \n",
        "      intent = get_intent_by_ml_model(question)\n",
        "      if intent is None:\n",
        "          intent = get_intent_by_model(question)                                      # 2. попытаться понять намерение с помощью ML-модели\n",
        "      if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "          print(random.choice(BOT_CONFIG['intents'][intent]['inc_response'])) \n",
        "      else: \n",
        "          print(random.choice(BOT_CONFIG['intents'][intent]['responses']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shite\n",
            "6\n",
            "wank\n",
            "8\n",
            "hous\n",
            "7\n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6dsrDPMjbcV"
      },
      "source": [
        "#\n",
        "# This is the bot which will run the AIML\n",
        "#\n",
        "def bot(question,choiceVar):\n",
        "    if question.find(cleaner('exit')) == -1:   \n",
        "        if choiceVar == 0:\n",
        "            bot_rc_ml1(question)\n",
        "        else if choiceVar == 1:\n",
        "            bot_rf_ml1(question)\n",
        "        else if choiceVar == 2:\n",
        "            bot_rf_ml2(question)\n",
        "        else:\n",
        "            bot_sgd_ml1(question) \n",
        "        #intent = get_intent(question)                                          1. попытаться понять намерение сравнением по Левинштейну\n",
        "    \n",
        "        #if intent is None:\n",
        "        #    print(\"intent was none\")\n",
        "        #    intent = get_intent_by_ml_model(question)                          2. попытаться понять намерение с помощью ML-модели\n",
        "        #    if choiceVar == 0:\n",
        "                  \n",
        "        #if 'inc_response' in BOT_CONFIG['intents'][intent]:\n",
        "        #    return random.choice(BOT_CONFIG['intents'][intent]['inc_response']) \n",
        "        #else: \n",
        "        #    return random.choice(BOT_CONFIG['intents'][intent]['responses'])\n",
        "    else:\n",
        "        return 'exit'      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnwEr8ohjtdr",
        "outputId": "965692de-5ae9-4a45-e01f-50653970d889"
      },
      "source": [
        "#\n",
        "# test it here\n",
        "#\n",
        "choiceVar = 0\n",
        "question = ''\n",
        "while question != 'exit':\n",
        "  question = input()\n",
        "  print(bot(question,choiceVar))\n",
        "  choiceVar = choiceVar + 1\n",
        "  choiceVar = choiceVar % 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question\n",
            "intent was none\n",
            "7\n",
            "club\n",
            "1\n",
            "exit\n",
            "intent was none\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7p7PtGzkewq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "bcf76d29-e9e5-47f1-f707-e4d63e5a2c90"
      },
      "source": [
        "pip install python-telegram-bot --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/50/b6b14ae91af8cf27798bad2e0bc214133009aae62bafe5136b051a17ba98/python_telegram_bot-13.7-py3-none-any.whl (490kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Collecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2021.5.30)\n",
            "Collecting tornado>=6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/a8/9c5902233fa3c2e6a889cbd164333ddda5009669f494e3fadbeee2c03af5/tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 30.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: APScheduler, tornado, python-telegram-bot\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "Successfully installed APScheduler-3.6.3 python-telegram-bot-13.7 tornado-6.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuaT9rmGkjZw"
      },
      "source": [
        "import logging\n",
        "\n",
        "from telegram import Update, ForceReply\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "# Enable logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "questions = []\n",
        "\n",
        "# Define a few command handlers. These usually take the two arguments update and\n",
        "# context.\n",
        "def start(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
        "    user = update.effective_user\n",
        "    update.message.reply_markdown_v2(\n",
        "        fr'Hi {user.mention_markdown_v2()}\\!',\n",
        "        reply_markup=ForceReply(selective=True),\n",
        "    )\n",
        "\n",
        "\n",
        "def help_command(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
        "    reply = '/content/sample_data/README.md'\n",
        "    update.message.reply_text(reply)\n",
        "\n",
        "\n",
        "def echo(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Echo the user message.\"\"\"\n",
        "    question = update.message.text\n",
        "    questions.append(question)\n",
        "    reply = bot(question,choiceVar)\n",
        "    choiceVar = choiceVar + 1\n",
        "    choiceVar = choiceVar % 5\n",
        "    # to send a file ..... reply = 'https://colab.research.google.com/drive/1Azj_M62pXee_7DlknRx7nEqEB2j7SoFp#scrollTo=zuaT9rmGkjZw'\n",
        "    if not reply.find(\"list\") == -1 or not reply.find(\"reply\") == -1:\n",
        "        #reply = '/content/sample_data/BT012.jpg'\n",
        "        update,message.reply_text(reply)\n",
        "    else:\n",
        "        replyurl = '127.0.0.1:8080/redirect/' + reply\n",
        "        update.message.reply_text(replyurl)      \n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"Start the bot.\"\"\"\n",
        "    # Create the Updater and pass it your bot's token.\n",
        "    updater = Updater(\"1778043544:AAE7NZYNTOqLMWmSFB0jGIv2-vFuNxgBz68\")\n",
        "\n",
        "    # Get the dispatcher to register handlers\n",
        "    dispatcher = updater.dispatcher\n",
        "\n",
        "    # on different commands - answer in Telegram\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
        "\n",
        "    # on non command i.e message - echo the message on Telegram\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
        "\n",
        "    # Start the Bot\n",
        "    updater.start_polling()\n",
        "\n",
        "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
        "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
        "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
        "    updater.idle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdmmi1YlcQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57dbe86-ae1b-4b64-dfa5-1749b39b686d"
      },
      "source": [
        "#\n",
        "# run communication to the botFather\n",
        "#\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-13 14:27:45,658 - apscheduler.scheduler - INFO - Scheduler started\n",
            "2021-07-13 14:28:38,144 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
            "2021-07-13 14:28:38,152 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}